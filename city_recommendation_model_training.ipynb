{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 城市推荐系统模型训练\n",
        "\n",
        "本Notebook用于训练城市推荐系统的模型，包括数据预处理、聚类分析和回归模型训练等步骤。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 导入必要的库"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 设置并行线程数，避免内存溢出\n",
        "os.environ['OMP_NUM_THREADS'] = '1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 数据加载函数\n",
        "\n",
        "该函数用于加载城市数据集，并进行基本的错误处理。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    try:\n",
        "        # 加载数据\n",
        "        df = pd.read_csv('updated_city_happiness.csv', encoding='utf-8-sig')\n",
        "        return df\n",
        "    except FileNotFoundError:\n",
        "        print('数据文件未找到，请检查文件路径和文件名。')\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 数据预处理函数\n",
        "\n",
        "该函数用于提取特征并进行标准化处理，为聚类分析做准备。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_data(df):\n",
        "    # 提取特征\n",
        "    features = df[['人均可支配收入(万元)', '房价收入比', '教育满意度(10分制)', '医疗资源指数', \n",
        "                   'PM2.5年均值', '公园绿地面积(㎡/人)', '养老保险覆盖率(%)', '每万人警力数', \n",
        "                   '通勤时间(分钟)']]\n",
        "\n",
        "    # 对特征进行标准化\n",
        "    scaler = StandardScaler()\n",
        "    features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "    return features_scaled, scaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 寻找最佳聚类数函数\n",
        "\n",
        "该函数使用轮廓系数法寻找最佳的聚类数量，提高聚类效果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_best_k(features_scaled):\n",
        "    # 使用轮廓系数法选择最佳的簇数\n",
        "    silhouette_scores = []\n",
        "    for k in range(2, 11):\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "        kmeans.fit(features_scaled)\n",
        "        labels = kmeans.labels_\n",
        "        score = silhouette_score(features_scaled, labels)\n",
        "        silhouette_scores.append(score)\n",
        "\n",
        "    # 获取最佳簇数\n",
        "    best_k = silhouette_scores.index(max(silhouette_scores)) + 2\n",
        "    return best_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 执行聚类函数\n",
        "\n",
        "该函数使用最佳聚类数对城市数据进行聚类，并将聚类结果添加到数据集中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_clustering(df, features_scaled, best_k):\n",
        "    # 使用最佳簇数进行K-means聚类\n",
        "    kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
        "    df['Cluster'] = kmeans.fit_predict(features_scaled)\n",
        "    return kmeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 构建并保存模型函数\n",
        "\n",
        "该函数为每个聚类构建随机森林回归模型，用于预测幸福指数，并保存模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_and_save_models(df):\n",
        "    # 为每个聚类构建随机森林回归模型并预测幸福指数\n",
        "    models = {}\n",
        "    for cluster in df['Cluster'].unique():\n",
        "        cluster_data = df[df['Cluster'] == cluster]\n",
        "        X = cluster_data[['人均可支配收入(万元)', '房价收入比', '教育满意度(10分制)', '医疗资源指数', \n",
        "                          'PM2.5年均值', '公园绿地面积(㎡/人)', '养老保险覆盖率(%)', '每万人警力数', \n",
        "                          '通勤时间(分钟)']]\n",
        "        y = cluster_data['幸福指数']\n",
        "\n",
        "        # 划分训练集和测试集\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # 构建随机森林回归模型\n",
        "        rf = RandomForestRegressor(random_state=42)\n",
        "        rf.fit(X_train, y_train)\n",
        "\n",
        "        # 保存模型\n",
        "        models[cluster] = rf\n",
        "\n",
        "    # 保存随机森林模型字典\n",
        "    joblib.dump(models, 'suijisenlinzidian.pkl')\n",
        "    return models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 主函数\n",
        "\n",
        "该函数整合了上述所有步骤，完成从数据加载到模型训练和保存的全过程。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "成功加载数据，共221条记录\n",
            "正在进行数据预处理...\n",
            "正在寻找最佳聚类数...\n",
            "最佳聚类数为: 2\n",
            "正在执行聚类分析...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "正在保存处理后的数据集...\n",
            "正在构建回归模型...\n",
            "模型训练和数据处理完成，已保存带有Cluster列的数据集\n",
            "生成的文件包括:\n",
            "- kmeans_model.pkl: K-means聚类模型\n",
            "- TeZhengBiaoZhunHua.pkl: 特征标准化模型\n",
            "- suijisenlinzidian.pkl: 随机森林回归模型字典\n",
            "- updated_city_happiness_with_cluster.csv: 带有聚类结果的数据集\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    df = load_data()\n",
        "    if df is not None:\n",
        "        print(f'成功加载数据，共{len(df)}条记录')\n",
        "\n",
        "        # 数据预处理\n",
        "        print('正在进行数据预处理...')\n",
        "        features_scaled, scaler = preprocess_data(df)\n",
        "\n",
        "        # 寻找最佳聚类数\n",
        "        print('正在寻找最佳聚类数...')\n",
        "        best_k = find_best_k(features_scaled)\n",
        "        print(f'最佳聚类数为: {best_k}')\n",
        "\n",
        "        # 执行聚类\n",
        "        print('正在执行聚类分析...')\n",
        "        kmeans = perform_clustering(df, features_scaled, best_k)\n",
        "\n",
        "        # 保存K-means模型和缩放器\n",
        "        joblib.dump(kmeans, 'kmeans_model.pkl')\n",
        "        joblib.dump(scaler, 'TeZhengBiaoZhunHua.pkl')\n",
        "\n",
        "        # 保存带有Cluster列的数据集\n",
        "        print('正在保存处理后的数据集...')\n",
        "        df.to_csv('updated_city_happiness_with_cluster.csv', index=False)\n",
        "\n",
        "        # 构建并保存回归模型\n",
        "        print('正在构建回归模型...')\n",
        "        build_and_save_models(df)\n",
        "\n",
        "        print('模型训练和数据处理完成，已保存带有Cluster列的数据集')\n",
        "        print('生成的文件包括:')\n",
        "        print('- kmeans_model.pkl: K-means聚类模型')\n",
        "        print('- TeZhengBiaoZhunHua.pkl: 特征标准化模型')\n",
        "        print('- suijisenlinzidian.pkl: 随机森林回归模型字典')\n",
        "        print('- updated_city_happiness_with_cluster.csv: 带有聚类结果的数据集')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 运行模型训练\n",
        "\n",
        "执行以下代码块，开始模型训练过程。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "成功加载数据，共221条记录\n",
            "正在进行数据预处理...\n",
            "正在寻找最佳聚类数...\n",
            "最佳聚类数为: 2\n",
            "正在执行聚类分析...\n",
            "正在保存处理后的数据集...\n",
            "正在构建回归模型...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n",
            "c:\\Users\\15339\\.conda\\envs\\datascience\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "模型训练和数据处理完成，已保存带有Cluster列的数据集\n",
            "生成的文件包括:\n",
            "- kmeans_model.pkl: K-means聚类模型\n",
            "- TeZhengBiaoZhunHua.pkl: 特征标准化模型\n",
            "- suijisenlinzidian.pkl: 随机森林回归模型字典\n",
            "- updated_city_happiness_with_cluster.csv: 带有聚类结果的数据集\n"
          ]
        }
      ],
      "source": [
        "# 运行模型训练\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "datascience",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
